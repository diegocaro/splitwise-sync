{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744ca8f-f868-477b-ba8f-62b1aa631f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_transactions_locs = pd.read_pickle(\"processed/matched_transactions_locs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e4c9a",
   "metadata": {},
   "source": [
    "# Model to predict personal or shared transaction\n",
    "\n",
    "1. Tag expenses as personal or shared using Splitwise\n",
    "1a. Tag deleted expenses as feedback for not shared \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f927ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = matched_transactions_locs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3699f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_weekend\"] = df[\"transaction_date\"].dt.dayofweek >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af314ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_cols = [\"location_address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"transaction_cost\",\n",
    "    \"transaction_date\",\n",
    "    \"transaction_description\",\n",
    "    \"is_weekend\",\n",
    "]\n",
    "df[df[\"is_shared\"]][features + desc_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description_comuna\"] = df[\"transaction_description\"].str[23:37].str.strip()\n",
    "df[\"description_pais\"] = df[\"transaction_description\"].str[37:45].str.strip()\n",
    "df[\"merchant_name\"] = df[\"transaction_description\"].str[0:23].str.strip()\n",
    "df[\"merchant_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description_pais\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing features for the decision tree model\n",
    "\n",
    "# 1. Transaction cost is ready to use\n",
    "\n",
    "# 2. Extract useful features from transaction_date\n",
    "df[\"transaction_month\"] = df[\"transaction_date\"].dt.month\n",
    "df[\"transaction_hour\"] = df[\"transaction_date\"].dt.hour\n",
    "df[\"transaction_dayofweek\"] = df[\"transaction_date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transaction_description\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c062b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_df(features, vectorizer, suffix):\n",
    "    \"\"\"Convert sparse matrix to DataFrame with appropriate column names.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        features.toarray(),\n",
    "        columns=[f\"{suffix}_{i}\" for i in vectorizer.get_feature_names_out()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Process transaction_description using text vectorization\n",
    "# We'll use a CountVectorizer to convert text descriptions to numerical features\n",
    "stop_words = [\"sumup\", \"merpago\", \"mercadopago\", \"spa\"]\n",
    "# stop_words = []\n",
    "vectorizer_description = CountVectorizer(\n",
    "    max_features=200, ngram_range=(2, 10), stop_words=stop_words\n",
    ")\n",
    "description_features = vectorizer_description.fit_transform(\n",
    "    df[\"merchant_name\"].fillna(\"\")\n",
    ")\n",
    "description_df = features_to_df(\n",
    "    description_features, vectorizer_description, \"merchant\"\n",
    ")\n",
    "vectorizer_description.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_merchant = CountVectorizer(\n",
    "    max_features=200, ngram_range=(2, 10), stop_words=stop_words\n",
    ")\n",
    "merchant_features = vectorizer_merchant.fit_transform(df[\"merchant_name\"].fillna(\"\"))\n",
    "merchant_df = features_to_df(merchant_features, vectorizer_merchant, \"merchant\")\n",
    "vectorizer_merchant.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c951250",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_comuna = CountVectorizer(\n",
    "    max_features=200, ngram_range=(1, 10), stop_words=stop_words\n",
    ")\n",
    "comuna_features = vectorizer_comuna.fit_transform(df[\"description_comuna\"].fillna(\"\"))\n",
    "description_df_comuna = features_to_df(comuna_features, vectorizer_comuna, \"comuna\")\n",
    "vectorizer_comuna.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_pais = CountVectorizer(\n",
    "    max_features=200, ngram_range=(1, 10), stop_words=stop_words\n",
    ")\n",
    "pais_features = vectorizer_pais.fit_transform(df[\"description_pais\"].fillna(\"\"))\n",
    "description_df_pais = features_to_df(pais_features, vectorizer_pais, \"pais\")\n",
    "vectorizer_pais.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36daf398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. is_weekend is already a boolean feature, ready to use\n",
    "\n",
    "# Combine all features\n",
    "numeric_features = df[\n",
    "    [\n",
    "        \"transaction_cost\",\n",
    "        \"transaction_month\",\n",
    "        \"transaction_hour\",\n",
    "        \"transaction_dayofweek\",\n",
    "        \"is_weekend\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Combine with text features\n",
    "X = pd.concat(\n",
    "    [\n",
    "        numeric_features.reset_index(drop=True),\n",
    "        description_df.reset_index(drop=True),\n",
    "        # merchant_df.reset_index(drop=True),\n",
    "        # description_df_comuna.reset_index(drop=True),\n",
    "        # description_df_pais.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y = df[\"is_shared\"].copy()\n",
    "\n",
    "# Display feature set\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"Class distribution: {y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Create the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(\n",
    "    max_depth=6, min_samples_split=5, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddc69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787867be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    dt_classifier,\n",
    "    filled=True,\n",
    "    feature_names=X.columns,\n",
    "    class_names=[\"Personal\", \"Shared\"],\n",
    "    rounded=True,\n",
    ")\n",
    "plt.title(\"Decision Tree for Transaction Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"Feature\": X.columns, \"Importance\": dt_classifier.feature_importances_}\n",
    ")\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    \"Importance\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "print(\"Feature Importance:\")\n",
    "display(feature_importance.head(15))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(\n",
    "    feature_importance[\"Feature\"].head(15), feature_importance[\"Importance\"].head(15)\n",
    ")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 15 Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Invert to have highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ff04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e5c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2dee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
